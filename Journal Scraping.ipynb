{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About API in Elsevier**\n",
    "- About text minig in Elsevier: https://dev.elsevier.com/tecdoc_text_mining.html\n",
    "- Get access to your personal API key: https://dev.elsevier.com/apikey/manage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JML ULR Format**\n",
    "- Old version (- August 2019): doi/10.1016/j.jml/2018.xx.xxx\n",
    "    - (a) xx is the month, which ranges from 00-12 (N.B.: two digit from 00 to 12)\n",
    "    - (b) xxx is the unique label of the paper, which ranges from 000- (N.B.: three digit from 000 to 999)\n",
    "    - (c) I haven't seen a case though that xxx exceeds 020. I thus used the range of 000-020 in my code\n",
    "- New version (October 2019 -): doi/10.106/j.jml/2019.xxxxxx\n",
    "    - xxxxxx is the unique label of the paper\n",
    "    - but the number is not in the order of publication\n",
    "\n",
    "**Just for my own note**\n",
    "- JML began to include a paper on computational modeling, as of Feb 2020\n",
    "\n",
    "**Summary for the code**\n",
    "- Old version: 2018.01.000 - 2019.12.019\n",
    "- New version: 2019.104027 - 2019.104059, 2020-104038 - 2020.104145 (as of July 1, 2020)\n",
    "    - These are the numbers that I extracted by eyeballing the unique label numbers published on the JML website\n",
    "- Because there are some missing numbers, I will code accordingly by looping through the range but pass the ones that do not host papers (i.e., returning HTTPError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The labels of the papers published online* (Not important here)\n",
    "\n",
    "2020 Oct\n",
    "2020.104132, 2020.104145, 2020.104144, 2020.104128, 2020.104125, 2020.104129, 2020.104130\n",
    "\n",
    "2020 Aug\n",
    "2020.104109, 2020.104110, 2020.104111, 2020.104106, 2020.104107, 2020.104113, 2020.104114, 2020.104124, 2020.104123, 2020.104126, 2020.104127\n",
    "\n",
    "2020 June\n",
    "2020.104088, 2020.104086, 2020.104089, 2020.104090, 2020.104092, 2020.104087, 2020.104105, 2020.104104, 2020.104108, 2020.104112, 2020.104091\n",
    "\n",
    "2020 April\n",
    "2020.104068, 2020.104082, 2020.104085, 2020.104084, 2020.104083, 2020.104063, 2020.104070, 2020.104069, 2020.104071\n",
    "\n",
    "2020 Feb\n",
    "2020.104065, 2020.104067, 2020.104064, 2020.104066, 2020.104038, 2020.104055, 2020.104052\n",
    "\n",
    "2019 Dec\n",
    "2019.104036, 2019.104047, 2019.104039, 2019.104050, 2019.104048, 2019.104049, 2019.104051, 2019.104054, 2019.104053\n",
    "\n",
    "2019 Oct\n",
    "2019.104028, 2019.104029, 2019.104030, 2019.104031, 2019.104027, 2019.104032, 2019.104034, 2019.104035, 2019.104037, 2019.104033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import urllib.error\n",
    "from urllib.request import urlopen as ureq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "from collections import Counter as Counter\n",
    "# import csv\n",
    "# import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting texts from Journal of Memory of Language (JML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Findinig the valid URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old DOI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = [f\"{i:02}\" for i in range(13)]\n",
    "month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_num_list = [f\"{i:03}\" for i in range(20)]\n",
    "unique_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_raw_old = []\n",
    "for year in range(2016, 2020):\n",
    "    for month in month_list:\n",
    "        for unique_num in unique_num_list:\n",
    "            url_string = 'https://api.elsevier.com/content/article/doi/10.1016/j.jml.%d.%s.%s?APIKey=13bf0ab31bf66221becf114979941195' %(year, month, unique_num)\n",
    "            url_raw_old.append(url_string)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_raw_old;\n",
    "len(url_raw_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New DOI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_raw_new = []\n",
    "for year in range(2019, 2021):\n",
    "    for unique_num in range(104027, 104146):\n",
    "        url_string = 'https://api.elsevier.com/content/article/doi/10.1016/j.jml.%d.%d?APIKey=13bf0ab31bf66221becf114979941195' %(year, unique_num)\n",
    "        url_raw_new.append(url_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_raw_new;\n",
    "len(url_raw_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_journal = url_raw_old + url_raw_new\n",
    "len(url_journal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the valid URLs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_url = []\n",
    "\n",
    "for i in url_journal:\n",
    "    try:\n",
    "        ureq(i)\n",
    "        print(\"The URL, %s is valid\" %i)\n",
    "        valid_url += [i]\n",
    "    except urllib.error.HTTPError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable **VALID_URL** for the \"untouched data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_URL = valid_url\n",
    "len(valid_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading the pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a test with a test_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = valid_url[3]\n",
    "test_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_url = ureq(test_url)\n",
    "page_html = client_url.read()\n",
    "client_url.close()\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "title = page_soup.find(\"dc:title\").text\n",
    "vol = page_soup.find(\"prism:volume\").text\n",
    "date = page_soup.find(\"prism:coverdisplaydate\").text\n",
    "month = date.split()[0]\n",
    "year = date.split()[1]\n",
    "abstract = page_soup.find(\"dc:description\").text\n",
    "abstract = abstract.replace(\"Abstract\",\"\").strip()\n",
    "keywords = page_soup.findAll(\"dcterms:subject\")\n",
    "keywords = str(keywords)\n",
    "doi = 'https://doi.org/' + page_soup.find(\"prism:doi\").text\n",
    "\n",
    "remove_string = [\"<dcterms:subject>\",\"</dcterms:subject>\",\"[\",\"]\"]\n",
    "\n",
    "for s in remove_string:\n",
    "    keywords = keywords.replace(s, \"\")\n",
    "    keywords = keywords.replace(\",\", \";\")\n",
    "\n",
    "test_dict = {'title': title, \n",
    "              'year': year, \n",
    "              'month': month,\n",
    "              'vol': vol,\n",
    "              'keywords': keywords,\n",
    "              'abstract': abstract,\n",
    "              'DOI': doi\n",
    "              }\n",
    "\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is eid** https://dev.elsevier.com/documentation/FullTextRetrievalAPI.wadl#d1e461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the extracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractJML(url_list):\n",
    "    \n",
    "    jml_dict = {}\n",
    "    \n",
    "    for i in url_list:\n",
    "        \n",
    "        # request client\n",
    "        client_url = ureq(i)\n",
    "        page_html = client_url.read()\n",
    "        client_url.close()\n",
    "        page_soup = soup(page_html, \"html.parser\")\n",
    "        \n",
    "        # get title\n",
    "        title = page_soup.find(\"dc:title\").text\n",
    "        \n",
    "        # get volume\n",
    "        vol = page_soup.find(\"prism:volume\").text\n",
    "        \n",
    "        # get date\n",
    "        date = page_soup.find(\"prism:coverdisplaydate\").text\n",
    "        month = date.split()[0]\n",
    "        year = date.split()[1]\n",
    "        \n",
    "        # get abstract\n",
    "        abstract = page_soup.find(\"dc:description\").text\n",
    "        abstract = abstract.replace(\"Abstract\",\"\").strip()\n",
    "        \n",
    "        # get keywords\n",
    "        keywords = page_soup.findAll(\"dcterms:subject\")\n",
    "        keywords = str(keywords)\n",
    "        remove_string = [\"<dcterms:subject>\",\"</dcterms:subject>\",\"[\",\"]\"]\n",
    "\n",
    "        for s in remove_string:\n",
    "            keywords = keywords.replace(s, \"\")\n",
    "            keywords = keywords.replace(\",\", \";\")\n",
    "        \n",
    "        # get doi\n",
    "        doi = 'https://doi.org/' + page_soup.find(\"prism:doi\").text\n",
    "        \n",
    "        # get eid\n",
    "        eid = page_soup.find(\"eid\").text\n",
    "        \n",
    "        # store in an embedded dictionary\n",
    "        jml_dict[eid] = {}\n",
    "        \n",
    "        jml_dict[eid]['title'] = title\n",
    "        jml_dict[eid]['year'] = year\n",
    "        jml_dict[eid]['month'] = month\n",
    "        jml_dict[eid]['volume'] = vol\n",
    "        jml_dict[eid]['keywords'] = keywords\n",
    "        jml_dict[eid]['abstract'] = abstract\n",
    "        jml_dict[eid]['DOI'] = doi\n",
    "        \n",
    "    return jml_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_urls = []\n",
    "test_urls.append(valid_url[3])\n",
    "test_urls.append(valid_url[5])\n",
    "test_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's extract the texts from JML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jml_dict = extractJML(valid_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(jml_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./JML_2016-2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Frequency count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Counter(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get the frequency of the keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "word_temp = []\n",
    "\n",
    "for i in range(len(counter(data))):\n",
    "    word_temp = data.iloc[2][i].split(\";\")\n",
    "    word_list += word_temp\n",
    "    \n",
    "word_list\n",
    "Counter(word_list).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_str = str(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = word_list[3].split(';')\n",
    "counter(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get the frequency of the **unique** keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cf. Basic example with one article from one URL (no loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check**\n",
    "- The url_journal is a wrong one, so should return a HTTP error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_journal = 'https://api.elsevier.com/content/article/doi/10.1016/j.jml.2019.104026?APIKey=13bf0ab31bf66221becf114979941195'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_journal = 'https://api.elsevier.com/content/article/doi/10.1016/j.jml.2019.104027?APIKey=13bf0ab31bf66221becf114979941195'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_url = ureq(url_journal)\n",
    "client_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_html = client_url.read()\n",
    "client_url.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup = soup(page_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = page_soup.find(\"dc:title\").text\n",
    "vol = page_soup.find(\"prism:volume\").text\n",
    "date = page_soup.find(\"prism:coverdisplaydate\").text\n",
    "eid = page_soup.find(\"eid\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = page_soup.find(\"dc:description\").text\n",
    "abstract = abstract.replace(\"Abstract\",\"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = page_soup.findAll(\"dcterms:subject\")\n",
    "keywords = str(keywords)\n",
    "\n",
    "remove_string = [\"<dcterms:subject>\",\"</dcterms:subject>\",\"[\",\"]\"]\n",
    "\n",
    "for s in remove_string:\n",
    "    keywords = keywords.replace(s, \"\")\n",
    "    keywords = keywords.replace(\",\", \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the code below -- I haven't worked on getting the author information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors = page_soup.findAll(\"dc:creator\")\n",
    "# authors = str(authors)\n",
    "\n",
    "# remove_string = [\"<dc:creator>\",\"</dc:creator>\",\"[\",\"]\"]\n",
    "\n",
    "# for s in remove_string:\n",
    "#     authors = authors.replace(s, \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
